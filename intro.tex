\section{Introduction}\label{section:intro}
Raft is a consensus algorithm designed for understandability and ease of implementation compared to the Paxos algorithm, and thus, it is widely utilized in various products to resolve consensus issues.

In distributed systems, Raft requires odd number of servers to always maintain a quorum that remains functional and communicative in case of network partition faults. Practically, this means a Raft cluster size should be at least three to tolerate a single point of failure.

While the requirement for an odd cluster size isn't problematic for large-scale distributed systems, it can pose a challenge for budget-constrained customers who need to reach consensus with fewer servers. One solution to this issue is to substitute one server in the cluster with a cost-effective entity known as a witness. The witness acts as a tie-breaker, ensuring the maintenance of a quorum in case of an even split of servers due to network issues. Witness typically operates on low-configuration hardware to save costs, seldom participates in critical data paths, and only persists a minimal amount of data. In the Paxos algorithm, a witness can be implemented as shared storage, which is not only inexpensive but also widely available to most customers.

Efforts have been undertaken to incorporate witness into Raft algorithm. For example, Diego Ongaro's Ph.D. dissertation explored the reduction of server numbers by using a witness to store log entries for any failed server until recovery or replacement. Jehan-François Pâris and Darrell D. E. Long proposed a type of follower-only server witness that doesn't persist user data. TiKV implements a witness in a similar manner as described by Ongaro: a log-only entity that persists only raft logs without applying them, and supports switching between witness and non-witness servers.

However, all existing research and implementations necessitate a standalone server as a witness, adding to deployment complexity and reducing cost-efficiency compared to shared storage in the Paxos algorithm. Additionally, the witness must participate in log replication when it needs to conform to a quorum with other servers (when some servers are down), implying that its low-configuration hardware could potentially become a performance bottleneck in such scenarios.
